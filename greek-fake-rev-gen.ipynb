{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-19T14:05:26.593069Z",
     "start_time": "2026-01-19T14:05:23.136395Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "import torch\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "import random\n",
    "import time\n",
    "from tqdm.notebook import tqdm"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.generativeai'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpandas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpd\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mgoogle\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mgenerativeai\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mgenai\u001B[39;00m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtransformers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m AutoTokenizer, pipeline\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'google.generativeai'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "load_dotenv()",
   "id": "7e495e03accebdc4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "api_key = os.getenv(\"GOOGLE_API_KEY\")",
   "id": "85179f9a75782051"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if not api_key:\n",
    "    raise ValueError(\"Δεν βρέθηκε το API Key! Βεβαιώσου ότι έχεις φτιάξει το αρχείο .env\")\n",
    "\n",
    "genai.configure(api_key=api_key)"
   ],
   "id": "c820d84255474d97"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "gemini_model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "print(\"✅ Το Gemini ρυθμίστηκε επιτυχώς με το κρυφό κλειδί.\")"
   ],
   "id": "d64a7883f8c35747"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Έλεγχος αν βλέπει την GPU\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"ΠΡΟΣΟΧΗ: Δεν βρέθηκε GPU. Ελέγξτε τους drivers.\")"
   ],
   "id": "fbe6c47b69a01c30"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ΦΟΡΤΩΣΗ LLAMA-KRIKRI\n",
    "model_id = \"ilsp/Llama-Krikri-8b-instruct\""
   ],
   "id": "4fe57b726f06c28"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(\"Φόρτωση μοντέλου στην GPU...\")",
   "id": "841c05c82e406285"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "    krikri_pipeline = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model_id,\n",
    "        model_kwargs={\n",
    "            \"torch_dtype\": torch.float16,\n",
    "            \"load_in_4bit\": True,\n",
    "            \"low_cpu_mem_usage\": True\n",
    "        },\n",
    "        device_map=\"auto\",\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "    print(\"Το Llama-KriKri φορτώθηκε επιτυχώς!\")\n",
    "except Exception as e:\n",
    "    print(f\"Σφάλμα φόρτωσης: {e}\")"
   ],
   "id": "898e4ca8b3d2895d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "INPUT_FILE = \"greek_dataset.xlsx - Φύλλο1.csv\"\n",
    "\n",
    "# Διάβασμα αρχείου\n",
    "try:\n",
    "    # Δοκιμή ως CSV (σύμφωνα με το όνομα του αρχείου που ανέβασες)\n",
    "    df_real = pd.read_csv(INPUT_FILE, on_bad_lines='skip')\n",
    "except:\n",
    "    # Fallback σε Excel engine αν χρειαστεί\n",
    "    df_real = pd.read_excel(INPUT_FILE)\n"
   ],
   "id": "25539bcb9840bd95"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Επιλογή στήλης 'review' και καθαρισμός\n",
    "if 'review' in df_real.columns:\n",
    "    df_real = df_real[['review']].dropna().copy()\n",
    "else:\n",
    "    # Αν για κάποιο λόγο δεν βρει το όνομα, παίρνουμε τη 2η στήλη\n",
    "    print(\"Η στήλη 'review' δεν βρέθηκε, χρησιμοποιείται η 2η στήλη.\")\n",
    "    df_real = df_real.iloc[:, 1].to_frame(name='review').dropna()"
   ],
   "id": "996dac18a63a0890"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Ανάθεση Label\n",
    "df_real['label'] = 'real'\n",
    "\n",
    "print(f\"Σύνολο Real Reviews: {len(df_real)}\")\n",
    "df_real.head(3)"
   ],
   "id": "dfeea89d84db0929"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def generate_fake_gemini():\n",
    "    \"\"\"Παραγωγή από Gemini\"\"\"\n",
    "    try:\n",
    "        sentiment = random.choice([\"θετική\", \"αρνητική\"])\n",
    "        # Prompt σχεδιασμένο για fake reviews\n",
    "        prompt = (\n",
    "            f\"Γράψε μια σύντομη {sentiment} κριτική (review) στα Ελληνικά για ένα προϊόν τεχνολογίας (π.χ. κινητό, laptop, gadget). \"\n",
    "            \"Γράψε την σαν να είσαι ένας απλός χρήστης που αγόρασε από e-shop. \"\n",
    "            \"Μην βάλεις τίτλο, μόνο το κυρίως κείμενο. Μην βάλεις εισαγωγικά.\"\n",
    "        )\n",
    "        response = gemini_model.generate_content(prompt)\n",
    "        return response.text.strip().replace('\"', '') # Καθαρισμός από τυχόν εισαγωγικά\n",
    "    except:\n",
    "        time.sleep(1)\n",
    "        return None"
   ],
   "id": "6c9de7920548f443"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def generate_fake_krikri():\n",
    "    \"\"\"Παραγωγή από Llama-KriKri\"\"\"\n",
    "    try:\n",
    "        sentiment = random.choice([\"θετική\", \"αρνητική\"])\n",
    "\n",
    "        # Chat format που καταλαβαίνει το μοντέλο instruct\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": f\"Γράψε μια σύντομη {sentiment} κριτική προϊόντος στα ελληνικά για ένα ηλεκτρονικό κατάστημα.\"}\n",
    "        ]\n",
    "\n",
    "        # Προετοιμασία prompt μέσω του tokenizer\n",
    "        prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "        outputs = krikri_pipeline(\n",
    "            prompt,\n",
    "            max_new_tokens=120,    # Μήκος κειμένου\n",
    "            do_sample=True,        # Δημιουργικότητα\n",
    "            temperature=0.8,\n",
    "            top_p=0.95,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "        # Καθαρισμός του αποτελέσματος (αφαιρούμε το prompt)\n",
    "        generated_text = outputs[0][\"generated_text\"]\n",
    "\n",
    "        # Συνήθως το instruct μοντέλο βάζει ειδικά tokens, προσπαθούμε να πάρουμε το τελευταίο κομμάτι\n",
    "        if \"<|assistant|>\" in generated_text:\n",
    "            return generated_text.split(\"<|assistant|>\")[-1].strip()\n",
    "        else:\n",
    "            # Fallback καθαρισμός\n",
    "            return generated_text.replace(prompt, \"\").strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"KriKri Error: {e}\")\n",
    "        return None"
   ],
   "id": "1c8c24671a27c479"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "num_real = len(df_real)\n",
    "num_fake_needed = num_real\n",
    "\n",
    "# Μοιράζουμε στη μέση\n",
    "half = num_fake_needed // 2\n",
    "fake_reviews = []\n",
    "\n",
    "print(f\"Στόχος: {num_fake_needed} fake reviews (Gemini: {half}, KriKri: {num_fake_needed - half})\")"
   ],
   "id": "30b5ea00c3629497"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --- 1. Gemini Loop ---\n",
    "print(\"Generating with Gemini...\")\n",
    "for _ in tqdm(range(half)):\n",
    "    res = generate_fake_gemini()\n",
    "    if res:\n",
    "        fake_reviews.append(res)\n",
    "    time.sleep(0.5) # Rate limiting protection"
   ],
   "id": "2ee5567c82631caf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --- 2. KriKri Loop ---\n",
    "print(\"Generating with Llama-KriKri...\")\n",
    "remaining = num_fake_needed - len(fake_reviews)\n",
    "\n",
    "for _ in tqdm(range(remaining)):\n",
    "    res = generate_fake_krikri()\n",
    "    if res:\n",
    "        fake_reviews.append(res)"
   ],
   "id": "feccc47155e81442"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Δημιουργία DataFrame\n",
    "df_fake = pd.DataFrame(fake_reviews, columns=['review'])\n",
    "df_fake['label'] = 'fake'\n",
    "\n",
    "print(f\"Ολοκληρώθηκε! Παρήχθησαν {len(df_fake)} fake reviews.\")"
   ],
   "id": "5139b26a98137f01"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Ένωση\n",
    "df_final = pd.concat([df_real, df_fake], ignore_index=True)"
   ],
   "id": "5fa7222ec149af98"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Shuffle (Ανακάτεμα)\n",
    "df_final = df_final.sample(frac=1).reset_index(drop=True)"
   ],
   "id": "c194c6c8cfb49d3e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Αποθήκευση\n",
    "OUTPUT_FILE = \"greek_fake_reviews_dataset.xlsx\"\n",
    "df_final.to_excel(OUTPUT_FILE, index=False)"
   ],
   "id": "314f46df2bfd6c19"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(f\"Το αρχείο σώθηκε ως: {OUTPUT_FILE}\")\n",
    "print(\"Κατανομή:\")\n",
    "print(df_final['label'].value_counts())"
   ],
   "id": "819b29099ac6bb53"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
