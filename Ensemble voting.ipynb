{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-05T22:22:02.453619Z",
     "start_time": "2025-12-05T22:22:02.448867Z"
    }
   },
   "source": [
    "# This script performs Soft Voting on the saved probabilities from the SVM and CNN-RNN models.\n",
    "# It assumes two files have been generated by Stages 1 and 2:\n",
    "# 1. 'svm_predictions_test.csv'\n",
    "# 2. 'cnn_rnn_predictions_test.csv'\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T22:22:03.249043Z",
     "start_time": "2025-12-05T22:22:03.241867Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"--- 1. Loading Predictions for Ensemble Voting ---\")",
   "id": "655a92076ef32ebb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Loading Predictions for Ensemble Voting ---\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T22:22:03.859314Z",
     "start_time": "2025-12-05T22:22:03.853820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the prediction file names\n",
    "svm_file = 'svm_predictions_test.csv'\n",
    "cnn_rnn_file = 'cnn_rnn_predictions_test.csv'"
   ],
   "id": "4bbf4df1ab4b933a",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T22:22:04.395224Z",
     "start_time": "2025-12-05T22:22:04.391146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize DataFrames outside the try block to avoid NameError if loading fails\n",
    "svm_df = pd.DataFrame()\n",
    "cnn_rnn_df = pd.DataFrame()"
   ],
   "id": "3f2c8c630b47bc67",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T22:28:12.491467Z",
     "start_time": "2025-12-05T22:28:12.454640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "    # Load SVM predictions (includes 'true_label' and 'svm_prob')\n",
    "    svm_df = pd.read_csv(svm_file)\n",
    "    print(f\"Loaded SVM predictions from {svm_file}\")\n",
    "\n",
    "    # Load CNN-RNN predictions (includes 'true_label' and 'cnn_rnn_prob')\n",
    "    cnn_rnn_df = pd.read_csv(cnn_rnn_file)\n",
    "    print(f\"Loaded CNN-RNN predictions from {cnn_rnn_file}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Cannot proceed. Please ensure the SVM and CNN-RNN scripts ran successfully and saved their prediction files.\")\n",
    "    exit()\n"
   ],
   "id": "30837941326b7d2a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded SVM predictions from svm_predictions_test.csv\n",
      "Loaded CNN-RNN predictions from cnn_rnn_predictions_test.csv\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T22:29:31.106729Z",
     "start_time": "2025-12-05T22:29:31.095647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def validate_predictions(df, required_cols, filename):\n",
    "    \"\"\"Checks if the necessary columns exist in the loaded DataFrame.\"\"\"\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"\\n--- ERROR: Column Mismatch in {filename} ---\")\n",
    "        print(f\"File Columns Found: {df.columns.tolist()}\")\n",
    "        print(f\"Missing Required Columns: {missing_cols}\")\n",
    "        print(\"Please rerun the corresponding model script (SVM or CNN-RNN) to generate the correct file.\")\n",
    "        exit()"
   ],
   "id": "1743201737acc676",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T22:30:04.521647Z",
     "start_time": "2025-12-05T22:30:04.517233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# If the program reached this point, the DataFrames should be successfully loaded.\n",
    "if svm_df.empty or cnn_rnn_df.empty:\n",
    "    print(\"\\nError: One or both prediction files were loaded but appear empty. Check the previous model steps.\")\n",
    "    exit()\n"
   ],
   "id": "2b4a878b3000b643",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T22:30:19.224277Z",
     "start_time": "2025-12-05T22:30:19.220248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Perform validation check before merging\n",
    "validate_predictions(svm_df, ['true_label', 'svm_prob'], svm_file)\n",
    "validate_predictions(cnn_rnn_df, ['true_label', 'cnn_rnn_prob'], cnn_rnn_file)"
   ],
   "id": "17d7ea38db7dea45",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T22:31:56.949110Z",
     "start_time": "2025-12-05T22:31:49.381653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2. Combine Predictions and Align Data\n",
    "\n",
    "# We merge the two prediction files using the shared 'true_label' column\n",
    "# This step ensures we are comparing predictions from the same test samples.\n",
    "ensemble_df = pd.merge(\n",
    "    svm_df[['true_label', 'svm_prob']],\n",
    "    cnn_rnn_df[['true_label', 'cnn_rnn_prob']],\n",
    "    on='true_label',\n",
    "    how='inner' # Only include samples present in both dataframes\n",
    ")\n",
    "Y_true = ensemble_df['true_label'].values\n",
    "print(f\"\\nCombined {len(ensemble_df)} test sample predictions.\")\n"
   ],
   "id": "b0c61f4eedc04234",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combined 32699785 test sample predictions.\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T22:32:48.311927Z",
     "start_time": "2025-12-05T22:32:48.305437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3. Soft Voting (Weighted Averaging) Ensemble\n",
    "print(\"\\n--- 3. Performing Soft Voting Ensemble ---\")"
   ],
   "id": "1bee2e3e10881650",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3. Performing Soft Voting Ensemble ---\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T22:33:42.740115Z",
     "start_time": "2025-12-05T22:33:42.732014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Determine optimal weights.\n",
    "# we will use weights based on their individual performance:\n",
    "# If CNN-RNN had 95% accuracy and SVM had 85% accuracy, the ratio of their weights\n",
    "# should be 95:85, or roughly 55% for CNN-RNN and 45% for SVM.\n",
    "\n",
    "# Example Weights (adjust these based on the actual accuracy results you got):\n",
    "W_SVM = 0.45\n",
    "W_CNN_RNN = 0.55\n",
    "print(f\"Ensemble Weights: SVM ({W_SVM:.2f}), CNN-RNN ({W_CNN_RNN:.2f})\")"
   ],
   "id": "501bb3374b9f5e6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Weights: SVM (0.45), CNN-RNN (0.55)\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T22:34:36.344580Z",
     "start_time": "2025-12-05T22:34:35.931516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate the final ensemble probability (Soft Voting)\n",
    "Y_ensemble_prob = (\n",
    "    (ensemble_df['svm_prob'] * W_SVM) +\n",
    "    (ensemble_df['cnn_rnn_prob'] * W_CNN_RNN)\n",
    ")"
   ],
   "id": "64332d2b4f556448",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T22:34:38.689203Z",
     "start_time": "2025-12-05T22:34:38.558909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert the ensemble probability to a class prediction (0 or 1) using a 0.5 threshold\n",
    "Y_ensemble_class = (Y_ensemble_prob > 0.5).astype(int)"
   ],
   "id": "b1ab34c64faa9331",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T22:35:37.231170Z",
     "start_time": "2025-12-05T22:35:17.536768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4. Final Evaluation of Ensemble Model\n",
    "\n",
    "print(\"\\n--- 4. Ensemble Model Evaluation ---\")\n",
    "\n",
    "# Calculate standard metrics\n",
    "ensemble_accuracy = accuracy_score(Y_true, Y_ensemble_class)\n",
    "ensemble_auc = roc_auc_score(Y_true, Y_ensemble_prob)\n",
    "print(f\"Overall Ensemble Accuracy: {ensemble_accuracy:.4f}\")\n",
    "print(f\"Overall Ensemble AUC Score: {ensemble_auc:.4f}\")"
   ],
   "id": "7fc5eee2fec9be48",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 4. Ensemble Model Evaluation ---\n",
      "Overall Ensemble Accuracy: 0.9709\n",
      "Overall Ensemble AUC Score: 0.9965\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T22:36:24.445963Z",
     "start_time": "2025-12-05T22:36:15.429016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the final Classification Report\n",
    "print(\"\\n--- Results: Ensemble Voting Classification Report ---\")\n",
    "print(classification_report(Y_true, Y_ensemble_class, target_names=['Real (0)', 'Fake (1)']))"
   ],
   "id": "8ef44bb0e0774731",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results: Ensemble Voting Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Real (0)       0.97      0.97      0.97  16353936\n",
      "    Fake (1)       0.97      0.97      0.97  16345849\n",
      "\n",
      "    accuracy                           0.97  32699785\n",
      "   macro avg       0.97      0.97      0.97  32699785\n",
      "weighted avg       0.97      0.97      0.97  32699785\n",
      "\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# You can now compare this report to the individual SVM and CNN-RNN reports\n",
    "# to show the improvement from the ensemble method."
   ],
   "id": "8c2a4fa442aabb94"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
